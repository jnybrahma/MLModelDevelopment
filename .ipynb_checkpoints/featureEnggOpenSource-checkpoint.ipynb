{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd392fc-026f-48ec-a6de-f4bf3f7567b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for the yeo-johnson transformation\n",
    "import scipy.stats as stats\n",
    "\n",
    "# to save the model for pipeline\n",
    "import joblib\n",
    "\n",
    "# from Scikit-learn\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "# from feature engine\n",
    "from feature_engine.imputation import(\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer,\n",
    ")\n",
    "\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "\n",
    "from feature_engine.transformation import (\n",
    "    LogTransformer,\n",
    "    YeoJohnsonTransformer,\n",
    ")\n",
    "\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "# to visualise all the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e0531-cc60-4ebb-b580-b69ebd9706f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# rows and columns of the data\n",
    "print(data.shape)\n",
    "\n",
    "# visualise the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4841ae-8f2d-4f4a-871f-73447e97b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data into train and test involves randomness, set the seed.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['Id', 'SalePrice'], axis=1), # predictive variables\n",
    "    data['SalePrice'], # target\n",
    "    test_size=0.1, # poertion of dataset to allocate to test set\n",
    "    random_state=0, # we are setting the seed here\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83c738-920a-42da-a208-ab10f1bc4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63582722-7c7e-4066-90e8-a082c55ae05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "# let's identify the categorical variables\n",
    "# we will capture those type object\n",
    "\n",
    "cat_vars = [var for var in data.columns if data[var].dtype == 'O']\n",
    "\n",
    "# MSSubClass us also categorical by definition, despite its numeric values\n",
    "# (you can find the definitions of the variables in the data_description.txt\n",
    "# file avaialble on Kaggle, in the same websote where you can download the data)\n",
    "\n",
    "# lets add MSSubClass to the list of categorical variables\n",
    "\n",
    "cat_vars = cat_vars + ['MSSubClass']\n",
    "\n",
    "# cast all variables as categorical\n",
    "X_train[cat_vars] = X_train[cat_vars].astype('O')\n",
    "X_test[cat_vars] = X_test[cat_vars].astype('O')\n",
    "\n",
    "# number of categorical variables\n",
    "len(cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b9dfb-b50c-4f3e-ba49-943c34892e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the categorical variables that contain missing values\n",
    "\n",
    "cat_vars_with_na = [\n",
    "    var for var in cat_vars\n",
    "    if X_train[var].isnull().sum() > 0\n",
    "]\n",
    "\n",
    "# print percentage of missing values per variable\n",
    "\n",
    "X_train[cat_vars_with_na].isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2715702-c1e0-4e10-bc1e-78fb3df1eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to impute with the string missing\n",
    "with_string_missing = [\n",
    "    var for var in cat_vars_with_na if X_train[var].isnull().mean() > 0.1 ]\n",
    "\n",
    "# variables to impute with the most frequent category\n",
    "with_frequent_category = [\n",
    "    var for var in cat_vars_with_na if X_train[var].isnull().mean() < 0.1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9e578-1ddf-4a96-8e84-5fd35d21aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I print the values here, because it makes it easier for \n",
    "# later when we need to add this values to a config file for \n",
    "# deployment\n",
    "with_string_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdcf73-2ff7-410b-828b-4b49bd900d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_frequent_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ff5f2-4478-487c-8981-1b9ef6687783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with new label : \"Missing\"\n",
    "\n",
    "# set up the class\n",
    "cat_imputer_missing = CategoricalImputer(\n",
    "    imputation_method='missing', variables=with_string_missing)\n",
    "\n",
    "# fit the class to the train set\n",
    "cat_imputer_missing.fit(X_train)\n",
    "\n",
    "# the class learns and stores the parameters\n",
    "cat_imputer_missing.imputer_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b5b5d6-d4aa-41fe-bc1e-15fbdb793d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA by missing\n",
    "\n",
    "# IMPORTANT: note that we could store this class with joblib\n",
    "X_train = cat_imputer_missing.transform(X_train)\n",
    "X_test = cat_imputer_missing.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d2456-0baa-476f-9b64-660bad87ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with most frequent category\n",
    "\n",
    "# set up class\n",
    "cat_imputer_frequent = CategoricalImputer(\n",
    "    imputation_method='frequent', variables=with_frequent_category)\n",
    "\n",
    "# fit the class to the train set\n",
    "cat_imputer_frequent.fit(X_train)\n",
    "\n",
    "# the class learns and stores the parameters\n",
    "cat_imputer_frequent.imputer_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87954790-20b9-4024-8ac6-eef83a190e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA by missing\n",
    "\n",
    "# IMPORTANT: note that we could store this class with joblib\n",
    "X_train = cat_imputer_frequent.transform(X_train)\n",
    "X_test = cat_imputer_frequent.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf76e37-197b-4e6e-867e-805f64bb2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we have no missing information in the engineered variables\n",
    "\n",
    "X_train[cat_vars_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5bcc7-a6d9-477d-95b3-e40719877f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that test set does not contain null values in the engineered variables\n",
    "\n",
    "[var for var in cat_vars_with_na if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd8dc8-f1fe-4066-b533-a88808d8580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's identify the numerical variables\n",
    "\n",
    "num_vars = [\n",
    "    var for var in X_train.columns if var not in cat_vars and var !='SalePrice']\n",
    "\n",
    "# number of numerical variables\n",
    "len(num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef618b-b8b1-4e6a-a1ac-7e8ccfc4a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list the numerical variables that contain missing values\n",
    "vars_with_na =[\n",
    "    var for var in num_vars if X_train[var].isnull().sum() > 0]\n",
    "\n",
    "# print percentage of missing values per variable\n",
    "X_train[vars_with_na].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a86b2-e38a-4e77-b545-b6e3f6d43639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print , make life easier when we create the config\n",
    "vars_with_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc67d7-7a90-453e-ba3b-9d871d9c423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add  missing indicator\n",
    "\n",
    "missing_ind =  AddMissingIndicator(variables=vars_with_na)\n",
    "\n",
    "missing_ind.fit(X_train)\n",
    "\n",
    "X_train = missing_ind.transform(X_train)\n",
    "X_test = missing_ind.transform(X_test)\n",
    "\n",
    "# check the binary missing indicator variables\n",
    "X_train[['LotFrontage_na','MasVnrArea_na', 'GarageYrBlt_na']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4eaa9a-4975-4b01-89e6-c483c3193969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then replace missing data with the mean\n",
    "\n",
    "# set the imputer\n",
    "mean_imputer = MeanMedianImputer(\n",
    "    imputation_method='mean', variables=vars_with_na )\n",
    "\n",
    "# learn and store parameters from train set\n",
    "mean_imputer.fit(X_train)\n",
    "\n",
    "# the stored parameters\n",
    "mean_imputer.imputer_dict_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327da64-4e6a-428b-b69f-ca811be87c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mean_imputer.transform(X_train)\n",
    "X_test = mean_imputer.transform(X_test)\n",
    "\n",
    "# IMPORTANT: note that we could save the imputers with joblib\n",
    "\n",
    "# check that we have no more missing values in the engineered variables\n",
    "X_train[vars_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5f552-1bac-4bbf-8741-a1e514721f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  check that test set does not contain null values in the engineered variables\n",
    "[var for var in vars_with_na if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f6681-27b8-43cc-b2e9-2177fcfb8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the binary missing indicator variables\n",
    "X_train[['LotFrontage_na','MasVnrArea_na', 'GarageYrBlt_na']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36f829-59f9-4b49-887f-5a712f4a53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the time elapsed between those variables and the year in which the house was sold\n",
    "\n",
    "def elapsed_years(df, var):\n",
    "    # capture difference between the year variable\n",
    "    # and the year in which the house was sold\n",
    "    df[var] = df['YrSold'] - df[var]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fc94c-cf7b-4b4a-a0cc-bcf2bab02d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n",
    "    X_train = elapsed_years(X_train, var)\n",
    "    X_test = elapsed_years(X_test, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014deba0-f7c5-4aeb-9211-618e28f388e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we drop YrSold\n",
    "drop_features = DropFeatures(features_to_drop=['YrSold'])\n",
    "\n",
    "X_train = drop_features.fit_transform(X_train)\n",
    "X_test = drop_features.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ded01-6287-4505-af86-9951df8e4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transformer = LogTransformer(\n",
    "    variables=[\"LotFrontage\", \"1stFlrSF\", \"GrLivArea\"])\n",
    "\n",
    "X_train = log_transformer.fit_transform(X_train)\n",
    "X_test = log_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06fdc7-882c-4305-aa2e-667d2c30caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that test set does not contain null values in the engineered variables\n",
    "[var for var in [\"LotFrontage\", \"1stFlrSF\", \"GrLivArea\"] if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e9820-43bf-442b-9cc2-e349a616d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for train set\n",
    "[var for var in [\"LotFrontage\", \"1stFlrSF\", \"GrLivArea\"] if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8523b-e9d2-48a4-a80b-aae54610bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Yeo-Johnson transformer to LotArea\n",
    "\n",
    "yeo_transformer = YeoJohnsonTransformer(\n",
    "    variables=['LotArea'])\n",
    "\n",
    "X_train = yeo_transformer.fit_transform(X_train)\n",
    "X_test = yeo_transformer.transform(X_test)\n",
    "\n",
    "# the learned parameter\n",
    "yeo_transformer.lambda_dict_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3badf-0dc7-47f4-b55b-59a842c715df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check absence of na in the train set\n",
    "[var for var in X_train.columns if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ee04a-46eb-4750-98f9-a58207d09acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check absence of na in the test set\n",
    "[var for var in X_train.columns if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f766f-c772-475b-b11a-14d2ee9ab982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize skewed variables\n",
    "\n",
    "skewed = [\n",
    "    'BsmtFinSF2', 'LowQualFinSF', 'EnclosedPorch',\n",
    "    '3SsnPorch', 'ScreenPorch', 'MiscVal'\n",
    "]\n",
    "\n",
    "binarizer = SklearnTransformerWrapper(\n",
    "    transformer=Binarizer(threshold=0), variables=skewed\n",
    ")\n",
    "\n",
    "X_train = binarizer.fit_transform(X_train)\n",
    "X_test = binarizer.transform(X_test)\n",
    "\n",
    "X_train[skewed].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355415f-e5d2-4585-8131-73de48423ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables;\n",
    "# Apply mappings\n",
    "# Variables which values have an assigned order, related to quality.\n",
    "# re-map strings to number, which determine quality\n",
    "\n",
    "qual_mappings = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'Missing': 0, 'NA': 0}\n",
    "\n",
    "qual_vars = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "             'HeatingQC', 'KitchenQual', 'FireplaceQu',\n",
    "             'GarageQual', 'GarageCond',\n",
    "            ]\n",
    "for var in qual_vars:\n",
    "    X_train[var] = X_train[var].map(qual_mappings)\n",
    "    X_test[var] = X_test[var].map(qual_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e22928-b6b9-431e-b01e-032890e6d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_mappings ={'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
    "\n",
    "var = 'BsmtExposure'\n",
    "\n",
    "X_train[var] = X_train[var].map(exposure_mappings)\n",
    "X_test[var] = X_test[var].map(exposure_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2450a19-85a7-4983-98ab-c9163274667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_mappings = {'Missing': 0, 'NA': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "\n",
    "finish_vars = ['BsmtFinType1', 'BsmtFinType2']\n",
    "\n",
    "for var in finish_vars:\n",
    "    X_train[var] = X_train[var].map(finish_mappings)\n",
    "    X_test[var] = X_test[var].map(finish_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badaf6a-cd2e-4a16-b0f8-ccc126e8b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_mappings = {'Missing': 0, 'NA': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "\n",
    "var = 'GarageFinish'\n",
    "\n",
    "X_train[var] = X_train[var].map(garage_mappings)\n",
    "X_test[var] = X_test[var].map(garage_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355429bf-2d5c-4d42-99f0-3b99ce281836",
   "metadata": {},
   "outputs": [],
   "source": [
    "fence_mappings = {'Missing': 0, 'NA': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
    "\n",
    "var = 'Fence'\n",
    "X_train[var] = X_train[var].map(fence_mappings)\n",
    "X_test[var] = X_test[var].map(fence_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbaad65-5fba-46c6-9cd3-07a1629a9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na in the train set\n",
    "[var for var in X_train.columns if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634949b-9254-46b1-974f-af2a6c0595fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na in the data set\n",
    "\n",
    "with_null = [var for var in X_train.columns if X_train[var].isnull().sum() > 0]\n",
    "\n",
    "with_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d3643-6f7d-4fb9-a435-cf8e24ed2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Rare Labels\n",
    "# capture all quality variables\n",
    "# Removing Rare Labels\n",
    "# create a dictionary with most frequent categories per variable\n",
    "# note the amount of hard coding that I need to do\n",
    "\n",
    "# Can you think of an alternative? Perhaps we could have save this as a numpy pickle\n",
    "# and load it here, instead of hard-coding.\n",
    "\n",
    "# But that means that we need to go back to the Feature Engineering notebook, and change\n",
    "# the code so that we store the pickle. So there is still some code changes that we need\n",
    "\n",
    "\n",
    "frequent_ls ={\n",
    "'MSZoning': ['FV', 'RH', 'RL', 'RM'],\n",
    "    'Street': ['Pave'],\n",
    "    'Alley': ['Grvl', 'Missing', 'Pave'],\n",
    "    'LotShape': ['IR1', 'IR2', 'Reg'],\n",
    "    'LandContour': ['Bnk', 'HLS', 'Low', 'Lvl'],\n",
    "    'Utilities': ['AllPub'],\n",
    "    'LotConfig': ['Corner', 'CulDSac', 'FR2', 'Inside'],\n",
    "    'LandSlope': ['Gtl', 'Mod'],\n",
    "    'Neighborhood': ['Blmngtn', 'BrDale', 'BrkSide', 'ClearCr', 'CollgCr', 'Crawfor',\n",
    "                     'Edwards', 'Gilbert', 'IDOTRR', 'MeadowV', 'Mitchel', 'NAmes', 'NWAmes',\n",
    "                     'NoRidge', 'NridgHt', 'OldTown', 'SWISU', 'Sawyer', 'SawyerW',\n",
    "                     'Somerst', 'StoneBr', 'Timber'],\n",
    "\n",
    "    'Condition1': ['Artery', 'Feedr', 'Norm', 'PosN', 'RRAn'],\n",
    "    'Condition2': ['Norm'],\n",
    "    'BldgType': ['1Fam', '2fmCon', 'Duplex', 'Twnhs', 'TwnhsE'],\n",
    "    'HouseStyle': ['1.5Fin', '1Story', '2Story', 'SFoyer', 'SLvl'],\n",
    "    'RoofStyle': ['Gable', 'Hip'],\n",
    "    'RoofMatl': ['CompShg'],\n",
    "    'Exterior1st': ['AsbShng', 'BrkFace', 'CemntBd', 'HdBoard', 'MetalSd', 'Plywood',\n",
    "                    'Stucco', 'VinylSd', 'Wd Sdng', 'WdShing'],\n",
    "\n",
    "    'Exterior2nd': ['AsbShng', 'BrkFace', 'CmentBd', 'HdBoard', 'MetalSd', 'Plywood',\n",
    "                    'Stucco', 'VinylSd', 'Wd Sdng', 'Wd Shng'],\n",
    "\n",
    "    'MasVnrType': ['BrkFace', 'None', 'Stone'],\n",
    "    'Foundation': ['BrkTil', 'CBlock', 'PConc', 'Slab'],\n",
    "    'Heating': ['GasA', 'GasW'],\n",
    "    'CentralAir': ['N', 'Y'],\n",
    "    'Electrical': ['FuseA', 'FuseF', 'SBrkr'],\n",
    "    'Functional': ['Min1', 'Min2', 'Mod', 'Typ'],\n",
    "    'GarageType': ['Attchd', 'Basment', 'BuiltIn', 'Detchd'],\n",
    "    'PavedDrive': ['N', 'P', 'Y'],\n",
    "    'PoolQC': ['Missing'],\n",
    "    'MiscFeature': ['Missing', 'Shed'],\n",
    "    'SaleType': ['COD', 'New', 'WD'],\n",
    "    'SaleCondition': ['Abnorml', 'Family', 'Normal', 'Partial'],\n",
    "    'MSSubClass': ['20', '30', '50', '60', '70', '75', '80', '85', '90', '120', '160', '190'],\n",
    "    \n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2971cd-9a8d-416b-a888-8a6225afd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture all quality variables\n",
    "qual_vars = qual_vars + finish_vars + ['BsmtExposure', 'GarageFinish', 'Fence']\n",
    "\n",
    "# capture the remaining categorical variables\n",
    "# (those that we did not re-map)\n",
    "\n",
    "cat_others = [\n",
    "    var for var in cat_vars if var not in qual_vars\n",
    "]\n",
    "\n",
    "len(cat_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da34e6-dd47-430f-938c-3d145dbaa55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d2fe7-e1c2-43ea-9eeb-e2bf145601c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_encoder = RareLabelEncoder(tol=0.01, n_categories=1, variables=cat_others)\n",
    "\n",
    "# find common labels\n",
    "rare_encoder.fit(X_train)\n",
    "\n",
    "# the common labels are stored, we can save the class\n",
    "# and then use it later)\n",
    "\n",
    "rare_encoder.encoder_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c08c9-eb9a-4aff-ac3d-68103ebdd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = rare_encoder.transform(X_train)\n",
    "X_test = rare_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6354431-0a65-46e1-9713-a626b550bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical variables\n",
    "\n",
    "# set up the encoder\n",
    "cat_encoder = OrdinalEncoder(encoding_method='ordered', variables=cat_others)\n",
    "\n",
    "# create the mappings\n",
    "cat_encoder.fit(X_train, y_train)\n",
    "\n",
    "# mappings are stored and class  can be saved\n",
    "cat_encoder.encoder_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650882e2-e544-417f-9217-c73930566302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na in the train set\n",
    "[var for var in X_train.columns if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d585d0c-3126-4d7f-84b2-f23457f974e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na in the test set\n",
    "[var for var in X_test.columns if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5337e-a88e-4d01-9663-5ea7fdea3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let me show you what I mean by monotonic relationship\n",
    "# between labels and target\n",
    "\n",
    "def analyse_vars(train, y_train, var):\n",
    "    \n",
    "    # function plots median house sale price per encoded\n",
    "    # category\n",
    "    \n",
    "    tmp = pd.concat([X_train, np.log(y_train)], axis=1)\n",
    "    \n",
    "    tmp.groupby(var)['SalePrice'].median().plot.bar()\n",
    "    plt.title(var)\n",
    "    plt.ylim(2.2, 2.6)\n",
    "    plt.ylabel('SalePrice')\n",
    "    plt.show()\n",
    "    \n",
    "for var in cat_others:\n",
    "    analyse_vars(X_train, y_train, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3096a1-4bed-4ea4-9b99-03fc92140a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968a3a1-f1b5-428c-825a-30e98219bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#  fit  the scaler to the train set\n",
    "scaler.fit(X_train) \n",
    "\n",
    "# transform the train and test set\n",
    "\n",
    "# sklearn returns numpy arrays, so we wrap the\n",
    "# array with a pandas dataframe\n",
    "\n",
    "X_train = pd.DataFrame(\n",
    "    scaler.transform(X_train),\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_train.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7249d3-3f10-4dba-8f1e-c8306f000c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
